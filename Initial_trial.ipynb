{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d19a9a8",
   "metadata": {},
   "source": [
    "# Classification Algorithm:\n",
    "\n",
    "- Data Description.\n",
    "\n",
    "- Goal.\n",
    "    \n",
    "Using logistic regression to understand the demographics and other characteristics of a bank customers' that accept a credit card offer and that do not accept a credit card.\n",
    "\n",
    "Data cleaning, wrangling and EDA on a database relative to an automobile portfolio from an insurance company. The goal is to analyze the data and define a model that fits to do predictions. The the variable 'total claim amount' should be considered as a target."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1be6a16",
   "metadata": {},
   "source": [
    "## Importing used packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1633af2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "from sqlalchemy import create_engine\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "import getpass\n",
    "password = getpass.getpass()\n",
    "\n",
    "connection_string = 'mysql+pymysql://root:' + password + '@localhost/mid_project'\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3072bf27",
   "metadata": {},
   "source": [
    "## Getting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0801302c",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''SELECT *\n",
    "           FROM creditcardmarketing\n",
    "           ;'''\n",
    "\n",
    "data = pd.read_sql_query(query, engine)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a94e0de",
   "metadata": {},
   "source": [
    "## Cleaning/Wrangling/EDA\n",
    "\n",
    "- Change headers names.\n",
    "- Deal with NaN values.\n",
    "- Categorical Features.\n",
    "- Numerical Features.\n",
    "- Exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b040a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape, data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7d46b0",
   "metadata": {},
   "source": [
    "### Creating a function to clean the headers\n",
    "- Renaming the columns so they follow the PE8 (snake case)\n",
    "- Renaming the columns taking out non alphanumeric characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64a8311",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_header(df):\n",
    "        pattern = '[\\W]'\n",
    "        df.columns = [x.lower().replace(\" \", \"_\") for x in df.columns]\n",
    "        df.columns = [re.sub(pattern, \"\", x) for x in df.columns]\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e873b19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another way to clean the headers:\n",
    "def clean_headers(df):\n",
    "    df.columns = [x.lower().replace(\" \", \"_\") for x in df.columns]\n",
    "    num = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "    char = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm'\n",
    "            , 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
    "    keep = ['_']\n",
    "    cols = df.columns\n",
    "    new_col_names = []\n",
    "    for col in cols:\n",
    "        new_col = ''\n",
    "        for alphabet in col:\n",
    "            if (alphabet in num) or (alphabet in char) or (alphabet in keep):\n",
    "                new_col += alphabet\n",
    "        new_col_names.append(new_col)\n",
    "\n",
    "    df.columns = new_col_names\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e65eae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = clean_headers(data) #or clean_header(data)\n",
    "data.columns\n",
    "\n",
    "# If using the function clean_header(data)\n",
    "# it would be also necessary rename the remaining column with the character 'ï':\n",
    "# data.rename(columns={'ïcustomer_number':'customer_number'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052d6bf6",
   "metadata": {},
   "source": [
    "### NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad4a242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking NaN values\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7159a7df",
   "metadata": {},
   "source": [
    "### Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa6972c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary of the data\n",
    "data.describe().T.apply(lambda x: round(x,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7458180",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['customer_number'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1299820a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As the df has 17976 rows and 'nunique() = 17976' for column 'customer_number' this column was setted as an index\n",
    "data.set_index('customer_number')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7692ee3",
   "metadata": {},
   "source": [
    "### Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741264f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in data.select_dtypes('object'):\n",
    "    print(data[col].value_counts(), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f97351",
   "metadata": {},
   "source": [
    "## Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b279adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking how many 'offer_accepted' by 'income_level'\n",
    "pd.crosstab(data['offer_accepted'], data['income_level'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621dd343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking how many 'offer_accepted' by 'credit_rating'\n",
    "pd.crosstab(data['offer_accepted'], data['credit_rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc7d274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking how many 'offer_accepted' by 'own_your_home'\n",
    "pd.crosstab(data['offer_accepted'], data['own_your_home'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477fbf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the correlations\n",
    "corr_matrix=data.corr(method='pearson')  # default\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "ax = sns.heatmap(corr_matrix, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158deecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As the columns 'average_balance' and 'q1/2/3/4_balance' showed a high correlation they will be dropped\n",
    "data = data.drop(columns=['q1_balance', 'q2_balance', 'q3_balance', 'q4_balance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511a2cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in data.select_dtypes(np.number):\n",
    "    if col == 'customer_number':\n",
    "        pass\n",
    "    else:\n",
    "        sns.distplot(data[col])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f5f985",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in data.select_dtypes(np.number):\n",
    "    if col == 'customer_number':\n",
    "        pass\n",
    "    else:\n",
    "        sns.boxplot(data[col])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8e3cba",
   "metadata": {},
   "source": [
    "## Processing Data\n",
    "\n",
    "- Dealing with outliers.\n",
    "- Normalization.\n",
    "- Encoding Categorical Data.\n",
    "- Splitting into train set and test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7b2f3d",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d91b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxcox_transform(df):\n",
    "    numeric_cols = df.select_dtypes(np.number).columns\n",
    "    _ci = {column: None for column in numeric_cols}\n",
    "    for column in numeric_cols:\n",
    "        # since i know any columns should take negative numbers, to avoid -inf in df\n",
    "        df[column] = np.where(df[column]<=0, np.NAN, df[column]) \n",
    "        df[column] = df[column].fillna(df[column].mean())\n",
    "        transformed_data, ci = stats.boxcox(df[column])\n",
    "        df[column] = transformed_data\n",
    "        _ci[column] = [ci] \n",
    "    return df, _ci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98113e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I would like to apply the transormation only on the column 'average_balance'\n",
    "# , bc the other numerical ones have discrete occurrences\n",
    "# But is it boxcox a the proper transformation to apply once the curve has 2 humps?\n",
    "\n",
    "data['average_balance'] = np.where(data['average_balance']<=0, np.NAN, data['average_balance']) \n",
    "data['average_balance'] = data['average_balance'].fillna(data['average_balance'].mean())\n",
    "transformed_data, ci = stats.boxcox(data['average_balance'])\n",
    "data['average_balance'] = transformed_data\n",
    "#_ci['average_balance'] = [ci]\n",
    "\n",
    "sns.distplot(data['average_balance'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4f55b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "upper = np.percentile(data['average_balance'],75)\n",
    "lower = np.percentile(data['average_balance'],25)\n",
    "iqr = upper - lower\n",
    "upper_limit = upper + (1.5 * iqr)\n",
    "lower_limit = lower - (1.5 * iqr)\n",
    "data = data[(data['average_balance']>lower_limit) & (data['average_balance']<upper_limit)]\n",
    "\n",
    "sns.boxplot(data['average_balance'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a1dd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the size of the data loss after removing outliers\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfdb61fd",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed91160c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['offer_accepted']\n",
    "X = data.drop('offer_accepted', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baee5e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20aabdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1e94b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification = LogisticRegression(random_state=42, max_iter=1000)\n",
    "\n",
    "classification.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f86f46c",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ba843b",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77b0bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get predictions\n",
    "predictions = classification.predict(X_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88faad65",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, predictions) # normalize : {'true', 'pred', 'all'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a351f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_matrix = confusion_matrix(y_test, predictions, normalize='all')\n",
    "cf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff152de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(cf_matrix, annot=True, fmt='.2%', cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e347f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_names = ['True A', 'False A', 'False B', 'True B']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in cf_matrix.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in cf_matrix.flatten()/np.sum(cf_matrix)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(cf_matrix, annot=labels, fmt='', cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ba3b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# after get dummies\n",
    "data.corr()['offer_accepted'].sort_values(ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
